{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask R-CNN - Compare Weights\n",
    "\n",
    "Compare and check which weights have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import keras\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = \"C:\\\\Users\\\\Martin\\\\Documents\\\\LEGOFinder\\\\Keras\\\\lego_object_detection\\\\maskrcnn\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "from samples.lego import lego\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Lego trained weights\n",
    "LEGO_1_WEIGHTS_PATH = \"C:/Users/Martin/Google Drive/Colab/maskrcnn/snapshots/lego20200530T0450/mask_rcnn_lego_0020.h5\"\n",
    "LEGO_2_WEIGHTS_PATH = \"C:/Users/Martin/Google Drive/Colab/maskrcnn/snapshots/lego20200530T0450/mask_rcnn_lego_0025.h5\"\n",
    "\n",
    "# load either \"train\", \"val\" or \"eval\"\n",
    "# DATASET = \"eval\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = lego.LegoConfig()\n",
    "LEGO_DIR = os.path.join(ROOT_DIR, \"datasets\", \"lego\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class TrainingConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.8\n",
    "    USE_RPN_ROIS = True\n",
    "    USE_RANDOM_RPN_ROIS = False\n",
    "\n",
    "config = TrainingConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation dataset\n",
    "#dataset = lego.LegoDataset()\n",
    "#dataset.load_lego(LEGO_DIR, DATASET)\n",
    "\n",
    "# Must call before using the dataset\n",
    "#dataset.prepare()\n",
    "\n",
    "#print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "with tf.device(DEVICE):\n",
    "    model1 = modellib.MaskRCNN(mode=\"training\", model_dir=MODEL_DIR, config=config)\n",
    "    model2 = modellib.MaskRCNN(mode=\"training\", model_dir=MODEL_DIR, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to lego weights file\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", LEGO_1_WEIGHTS_PATH)\n",
    "model1.load_weights(LEGO_1_WEIGHTS_PATH, by_name=True)\n",
    "print(\"Loading weights \", LEGO_2_WEIGHTS_PATH)\n",
    "model2.load_weights(LEGO_2_WEIGHTS_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select Layers to Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_layers = \"heads\"\n",
    "\n",
    "layer_regex = {\n",
    "        # all layers but the backbone\n",
    "        \"heads\": r\"(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "        # From a specific Resnet stage and up\n",
    "        \"3+\": r\"(res3.*)|(bn3.*)|(res4.*)|(bn4.*)|(res5.*)|(bn5.*)|(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "        \"4+\": r\"(res4.*)|(bn4.*)|(res5.*)|(bn5.*)|(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "        \"5+\": r\"(res5.*)|(bn5.*)|(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "        # All layers\n",
    "        \"all\": \".*\",\n",
    "        \"all_but_rpn\": r\"^(?!rpn\\_).*\",\n",
    "        \"rpn\": r\"(rpn\\_.*)\",\n",
    "    }\n",
    "\n",
    "if selected_layers in layer_regex.keys():\n",
    "    selected_layers = layer_regex[selected_layers]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare Layer Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare weights layer by layer\n",
    "keras_model1 = model1.keras_model\n",
    "keras_model2 = model2.keras_model\n",
    "\n",
    "layers1 = keras_model1.inner_model.layers if hasattr(keras_model1, \"inner_model\") else keras_model1.layers\n",
    "layers2 = keras_model2.inner_model.layers if hasattr(keras_model2, \"inner_model\") else keras_model2.layers\n",
    "\n",
    "def check_layer(layer1, layer2, intend=0):\n",
    "\n",
    "    # check only layers that have been selected\n",
    "    selected = bool(re.fullmatch(selected_layers, layer1.name))\n",
    "    if not selected:\n",
    "        return\n",
    "\n",
    "    #log(\"{}{:20}   ({})\".format(\" \" * intend, layer1.name, layer1.__class__.__name__))\n",
    "\n",
    "    weights1 = layer1.get_weights()\n",
    "    weights2 = layer2.get_weights()\n",
    "\n",
    "    len_weights1 = len(weights1)\n",
    "    len_weights2 = len(weights2)\n",
    "\n",
    "    if len_weights1 != len_weights2:\n",
    "        print(\"4 - length mismatch: \" + layer1.name + \", \" + layer2.name)\n",
    "\n",
    "    # weights consist of further lists\n",
    "    weight_idx = 0\n",
    "    for weight1, weight2 in zip(weights1, weights2):\n",
    "\n",
    "        e = np.allclose(weight1, weight2, 1e-06, 1e-06) \n",
    "        if not e:\n",
    "            print(\"6 - weights mismatch: \" + layer1.name + \", \" + str(weight_idx))\n",
    "        weight_idx += 1\n",
    "\n",
    "for layer1, layer2 in zip(layers1, layers2):\n",
    "\n",
    "    # Is the layer a model?\n",
    "    if layer1.__class__.__name__ == 'Model':\n",
    "\n",
    "        assert layer2.__class__.__name__ == 'Model', \"2 - model mismatch.\"\n",
    "        \n",
    "        print(\"In model: \", layer1.name)\n",
    "\n",
    "        model1_layers = layer1.layers\n",
    "        model2_layers = layer2.layers\n",
    "        \n",
    "        len_model1 = len(model1_layers)\n",
    "        len_model2 = len(model2_layers)\n",
    "        \n",
    "        if len_model1 != len_model2:\n",
    "            print(\"3 - length mismatch.\")\n",
    "        \n",
    "        for l1, l2 in zip(model1_layers, model2_layers):\n",
    "\n",
    "            if not l1.weights:\n",
    "                continue\n",
    "\n",
    "            # Check layer. If layer is a container, update inner layer.\n",
    "            if l1.__class__.__name__ == 'TimeDistributed':\n",
    "                check_layer(l1.layer, l2.layer, intend=4)\n",
    "            else:\n",
    "                check_layer(l1, l2, intend=4)\n",
    "\n",
    "        continue\n",
    "\n",
    "    if not layer1.weights:\n",
    "        continue\n",
    "\n",
    "    # Check layer. If layer is a container, update inner layer.\n",
    "    if layer1.__class__.__name__ == 'TimeDistributed':\n",
    "        check_layer(layer1.layer, layer2.layer, intend=0)\n",
    "    else:\n",
    "        check_layer(layer1, layer2, intend=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.5 64-bit ('maskrcnn': conda)",
   "language": "python",
   "name": "python35564bitmaskrcnnconda12328bed15fa469aad72f1a08ed0d096"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}