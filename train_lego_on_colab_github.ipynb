{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_lego_on_colab_github.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1bY-SBU4jAUh_xHv67flCBt25w84ADq_j","authorship_tag":"ABX9TyMaPXE5cFdGs7p5/9XaMjCS"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fLPXfPJa7fGP"},"source":["#Install Large Files"]},{"cell_type":"markdown","metadata":{"id":"7o-5dAufk5vR"},"source":["Connect your Google Drive first! Press button on left side."]},{"cell_type":"code","metadata":{"id":"p6x979Bak-jC","executionInfo":{"status":"ok","timestamp":1601714912934,"user_tz":-120,"elapsed":1380,"user":{"displayName":"Martin W.","photoUrl":"https://lh3.googleusercontent.com/-ChCIqvE4jN4/AAAAAAAAAAI/AAAAAAAAAWw/3d45iQ6YnhU/s64/photo.jpg","userId":"03740598155738905535"}}},"source":["# Root directory of the project\n","ROOT_DIR = '/content/drive/My Drive/lego-cnn-master'"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"SONgsJ8o4P2u"},"source":["!pip install gdown\n","import gdown\n","\n","# Get example model weight\n","url = 'https://drive.google.com/uc?id=1XjDlMButvwsZsYauUGybhY5aCBA1tBjo'\n","output = ROOT_DIR + '/snapshots/lego20200717T1532/mask_rcnn_lego_0041.h5'\n","gdown.download(url, output, quiet=False)\n","\n","# Get dataset 6\n","url = 'https://drive.google.com/uc?id=1v4gsJ-2B3LQYKul6XNMrYCbZfIW0M1Wb'\n","output = ROOT_DIR + '/datasets/images6.zip'\n","gdown.download(url, output, quiet=False)\n","\n","# Get dateset 22\n","url = 'https://drive.google.com/uc?id=1ZmavdrcbDyLNiySJlFPSSpz5vABg1vod'\n","output = ROOT_DIR + '/datasets/images22.zip'\n","gdown.download(url, output, quiet=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ys32uuqgFgZX","executionInfo":{"status":"ok","timestamp":1601715124864,"user_tz":-120,"elapsed":32185,"user":{"displayName":"Martin W.","photoUrl":"https://lh3.googleusercontent.com/-ChCIqvE4jN4/AAAAAAAAAAI/AAAAAAAAAWw/3d45iQ6YnhU/s64/photo.jpg","userId":"03740598155738905535"}}},"source":["# Unzip the dataset that you want\n","unzip_dir = ROOT_DIR.replace(\" \",\"\\ \")\n","\n","!unzip -q $unzip_dir/datasets/images22.zip -d $unzip_dir/datasets\n","!mv $unzip_dir/datasets/images22/* $unzip_dir/datasets/lego/"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VHG9WuLyEhzR"},"source":["# Install Packages"]},{"cell_type":"code","metadata":{"id":"xPw7QfhdYANZ","executionInfo":{"status":"ok","timestamp":1601715124871,"user_tz":-120,"elapsed":14691,"user":{"displayName":"Martin W.","photoUrl":"https://lh3.googleusercontent.com/-ChCIqvE4jN4/AAAAAAAAAAI/AAAAAAAAAWw/3d45iQ6YnhU/s64/photo.jpg","userId":"03740598155738905535"}},"outputId":"762e358e-9dd3-42b2-a299-4144199bc715","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["%tensorflow_version 1.x"],"execution_count":5,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QmHNfggOEplU","executionInfo":{"status":"ok","timestamp":1601715129500,"user_tz":-120,"elapsed":18247,"user":{"displayName":"Martin W.","photoUrl":"https://lh3.googleusercontent.com/-ChCIqvE4jN4/AAAAAAAAAAI/AAAAAAAAAWw/3d45iQ6YnhU/s64/photo.jpg","userId":"03740598155738905535"}}},"source":["import os\n","import sys\n","\n","# Prepare colab environment and load images\n","os.system('pip install keras==2.2.4') # Must be 2.2.4 (or 2.3.0) otherwise get metrics_tensors error\n","os.system('python setup.py build_ext --inplace; pip install .')\n","os.chdir(ROOT_DIR)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pOzNdY-qs9Iu"},"source":["# Import Packages"]},{"cell_type":"code","metadata":{"id":"PBYeeLL6sK07","executionInfo":{"status":"ok","timestamp":1601715149950,"user_tz":-120,"elapsed":37072,"user":{"displayName":"Martin W.","photoUrl":"https://lh3.googleusercontent.com/-ChCIqvE4jN4/AAAAAAAAAAI/AAAAAAAAAWw/3d45iQ6YnhU/s64/photo.jpg","userId":"03740598155738905535"}},"outputId":"8ba06b6a-74a8-4a35-a708-5fbdfac17906","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import random\n","import math\n","import re\n","import time\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","# Import Mask RCNN\n","sys.path.append(ROOT_DIR)  # To find local version of the library\n","from mrcnn import utils\n","from mrcnn import visualize\n","from mrcnn.visualize import display_images\n","import mrcnn.model as modellib\n","from mrcnn.model import log\n","\n","from samples.lego import lego\n","\n","# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"cAaY3hgW1eFh"},"source":["# Infer RPN"]},{"cell_type":"markdown","metadata":{"id":"eUu7jJ9i2MFl"},"source":["### Load Configuration"]},{"cell_type":"code","metadata":{"id":"YiRhbr7V2Bxf"},"source":["LEGO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"snapshots\", \"lego20200717T1532\",\"mask_rcnn_lego_0041.h5\") # Comment out to use snapshot from latest training\n","\n","DATASET = \"eval\"\n","config = lego.LegoConfig()\n","LEGO_DIR = os.path.join(ROOT_DIR, \"datasets\", \"lego\")\n","\n","class InferenceConfig(config.__class__):\n","    # Run detection on one image at a time\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","\n","\n","config = InferenceConfig()\n","config.display()\n","\n","def get_ax(rows=1, cols=1, size=16):\n","    \"\"\"Return a Matplotlib Axes array to be used in\n","    all visualizations in the notebook. Provide a\n","    central point to control graph sizes.\n","    \n","    Adjust the size attribute to control how big to render images\n","    \"\"\"\n","    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n","    return ax"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xipHZzTm2O0l"},"source":["### Load Dataset"]},{"cell_type":"code","metadata":{"id":"w9xlxqeg2SWN"},"source":["dataset = lego.LegoDataset()\n","dataset.load_lego(LEGO_DIR, DATASET)\n","dataset.prepare()\n","print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UO32Cbk-2Uu-"},"source":["### Load Model and Weights"]},{"cell_type":"code","metadata":{"id":"d9AjL5Hx2afl"},"source":["model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n","print(\"Loading weights \", LEGO_WEIGHTS_PATH)\n","model.load_weights(LEGO_WEIGHTS_PATH, by_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VwU2faqU2dFV"},"source":["### RPN Analysis"]},{"cell_type":"code","metadata":{"id":"OCfZJ82l2fju"},"source":["if DATASET == \"eval\":\n","    image_id = dataset.get_image_id(\"0000000002.png\") # If eval set us the image with the Lego haufen\n","else:\n","    image_ids = np.random.choice(dataset.image_ids, 1)\n","    image_id = image_ids[0]\n","    \n","image, image_meta, gt_class_ids, gt_bboxes, gt_masks = modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1w0Yr5On2tT-"},"source":["# Run RPN sub-graph\n","if config.USE_RPN_ROIS:\n","    pillar = model.keras_model.get_layer(\"ROI\").output\n","\n","    # TF 1.4 and 1.9 introduce new versions of NMS. Search for all names to support TF 1.3~1.10\n","    nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression:0\")\n","    if nms_node is None:\n","        nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression/NonMaxSuppressionV2:0\")\n","    if nms_node is None: #TF 1.9-1.10\n","        nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression/NonMaxSuppressionV3:0\")\n","\n","    rpn = model.run_graph([image], [\n","        (\"rpn_class\", model.keras_model.get_layer(\"rpn_class\").output),         # Last layer in RPN with the proposed class probabilites for background or foreground per anchor\n","        (\"pre_nms_anchors\", model.ancestor(pillar, \"ROI/pre_nms_anchors:0\")),\n","        (\"refined_anchors\", model.ancestor(pillar, \"ROI/refined_anchors:0\")),\n","        (\"refined_anchors_clipped\", model.ancestor(pillar, \"ROI/refined_anchors_clipped:0\")),\n","        (\"post_nms_anchor_ix\", nms_node),                                       # Filtered anchors that have a NMS of RPN_NMS_THRESHOLD (>0.7)\n","        (\"proposals\", model.keras_model.get_layer(\"ROI\").output),               # \"ROI\" is the name of the ProposalLayers, the filtered rois proposals\n","    ], config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T0JHN1HD2mfF"},"source":["# Find the proposal that has the highest IoU on each GT box and take average of all\n","max_proposals_bbox = np.empty((gt_bboxes.shape[0], 4))\n","max_proposals_iou = np.empty((gt_bboxes.shape[0], 1))\n","\n","# Get proposals from graph\n","h, w = config.IMAGE_SHAPE[:2]\n","proposals = rpn['proposals'][0, :] * np.array([h, w, h, w])\n","\n","print(\"Best proposals are:\\n\")\n","for i, box in enumerate(gt_bboxes):\n","\n","    overlaps = utils.compute_overlaps(np.array([box.tolist()]), proposals)\n","    iou_max = np.max(overlaps, axis=1)\n","    iou_argmax = np.argmax(overlaps, axis=1)\n","    max_proposals_bbox[i] = proposals[iou_argmax]\n","    max_proposals_iou[i] = iou_max\n","\n","    y1, x1, y2, x2 = proposals[iou_argmax][0]\n","    iou = iou_max[0]\n","\n","    print(\"Proposal Bbox {}: \\t[{:.0f} {:.0f} {:.0f} {:.0f}] w={:.0f} h={:.0f} iou={:.2f}\".format(i, x1, y1, x2, y2, x2-x1, y2-y1, iou))\n","\n","\n","print(\"\\nAverage maximum IoU is: {0:0.2f}\".format(np.average(max_proposals_iou)))\n","visualize.draw_boxes(image, boxes=gt_bboxes, refined_boxes=max_proposals_bbox)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZiSucU-Fzj1h"},"source":["# Run Evaluation"]},{"cell_type":"code","metadata":{"id":"96KLDjuHznfF"},"source":["# Compute VOC-Style mAP @ IoU=0.5\n","APs = []\n","TPs = []\n","FPs = []\n","total_instances = 0\n","\n","# IoU threshold to determine a postive match\n","mAP_IOU_THRESHOLD = 0.5\n","\n","if DATASET == \"eval\":\n","    image_ids = dataset.image_ids\n","else:\n","    image_ids = np.random.choice(dataset.image_ids, 5 if config.USE_STAGE_TWO else 1)\n","\n","for image_id in image_ids:\n","\n","    # Load image and ground truth data\n","    image, image_meta, gt_class_ids, gt_bboxes, gt_masks =  modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n","\n","    # Run object detection\n","    results = model.detect([image], gt_class_ids, gt_bboxes, gt_masks, verbose=0)\n","    r = results[0]\n","\n","    ax = get_ax(1)\n","    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], dataset.class_names, gt_bboxes, gt_class_ids, \n","                                r['scores'], ax=ax, title=\"Predictions\")\n","\n","    # Compute AP, IoU ist mit den Masken berechnet, nicht mit Bboxen\n","    AP, precisions, recalls, overlaps, true_positives, false_positives = utils.compute_ap(  gt_bboxes, gt_class_ids, gt_masks,    \n","                                                                                            r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'],\n","                                                                                            iou_threshold=mAP_IOU_THRESHOLD)\n","    if true_positives == 0 and false_positives == 0:\n","        print(\"\\n*** No instances matched in {} *** \\n\".format(dataset.image_info[image_id][\"id\"]))\n","        \n","    APs.append(AP)\n","    TPs.append(true_positives)\n","    FPs.append(false_positives)\n","    total_instances += len(gt_bboxes)\n","\n","tps = int(np.sum(TPs))\n","fps = int(np.sum(FPs))\n","\n","print('TP: {:2.0f}   FP: {:2.0f}   TP/FP: {:2.1f}   TP/Total: {:2.0f}%'.format(tps, fps, 0 if fps == 0 else (tps/fps), 0 if total_instances == 0 else (100.0/total_instances)*tps))\n","print(\"mAP@\" + str(mAP_IOU_THRESHOLD)+ \": \", np.mean(APs))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z4wL5a6mHiHC"},"source":["\n","# Train CNN"]},{"cell_type":"code","metadata":{"id":"YfLuKRqyZqGR"},"source":["import samples.lego.lego\n","import mrcnn.model\n","import mrcnn.utils\n","import mrcnn.config\n","import imp\n","\n","# If you change code on the fly, reload modules\n","import imp\n","imp.reload(mrcnn.config)\n","imp.reload(samples.lego.lego)\n","imp.reload(mrcnn.model)\n","imp.reload(mrcnn.utils)\n","\n","from samples.lego.lego import main as tmain\n","from google.cloud import storage\n","\n","# Configuration section\n","PATH_DATASET                = os.path.join('datasets', 'lego')\n","USE_PREV_WEIGHTS\t\t\t      = False # Set to True if you want to restart from a previous session\n","NB_OF_EPOCHS                = 1 # Typically 40 epoches are sufficient for this project, \n","\n","# Where are we\n","print('\\Script running in: ' + os.getcwd())\n","print(\"Python version: \" + sys.version)\n","print(\"Python install path: \" + sys.executable)\n","\n","# Show tool version\n","import tensorflow\n","print(tensorflow.__version__)\n","import keras\n","print(keras.__version__)\n","\n","\n","# Call train function\n","if USE_PREV_WEIGHTS:\n","    LEGO_WEIGHTS_PATH = tmain([ 'train', '--dataset=' + PATH_DATASET, '--logs=snapshots', '--enable-augmentation', '--weights=last','--epochs=' + str(NB_OF_EPOCHS)])\n","else:\n","    LEGO_WEIGHTS_PATH = tmain([ 'train', '--dataset=' + PATH_DATASET, '--logs=snapshots','--enable-augmentation', '--epochs=' + str(NB_OF_EPOCHS)])\n"],"execution_count":null,"outputs":[]}]}