{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_lego_on_colab","provenance":[],"collapsed_sections":["tOoY9sJ_K1Sy"],"machine_shape":"hm","mount_file_id":"14xaIXLgYt3A5LTy5tMByJkujAVC_571b","authorship_tag":"ABX9TyOcdF57C9Ez6Uwt4SEU+PcL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VHG9WuLyEhzR"},"source":["# Install Packages"]},{"cell_type":"code","metadata":{"id":"xPw7QfhdYANZ","executionInfo":{"status":"ok","timestamp":1601212455153,"user_tz":-120,"elapsed":660,"user":{"displayName":"Martin W.","photoUrl":"https://lh3.googleusercontent.com/-ChCIqvE4jN4/AAAAAAAAAAI/AAAAAAAAAWw/3d45iQ6YnhU/s64/photo.jpg","userId":"03740598155738905535"}}},"source":["%tensorflow_version 1.x"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"QmHNfggOEplU"},"source":["import os\n","import sys\n","\n","# Prepare colab environment and load images\n","os.system('pip install keras==2.2.4') # Must be 2.2.4 (or 2.3.0) otherwise get metrics_tensors error\n","os.system('python setup.py build_ext --inplace; pip install .')\n","os.chdir('/content/drive/My Drive/Colab/maskrcnn')\n","#os.system('pip install keras-resnet')\n","\n","#import keras_resnet\n","#import keras_resnet.models"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z4wL5a6mHiHC"},"source":["\n","# Train CNN"]},{"cell_type":"code","metadata":{"id":"YfLuKRqyZqGR"},"source":["import samples.lego.lego\n","import mrcnn.model\n","import mrcnn.utils\n","import mrcnn.config\n","\n","import imp\n","imp.reload(mrcnn.config)\n","imp.reload(samples.lego.lego)\n","imp.reload(mrcnn.model)\n","imp.reload(mrcnn.utils)\n","\n","from samples.lego.lego import main as tmain\n","from google.cloud import storage\n","\n","# Configuration section\n","\n","PATH_DATASET                = os.path.join('datasets', 'lego')\n","USE_PREV_WEIGHTS\t\t\t      = False\n","NB_OF_EPOCHS                = 20\n","\n","# Where are we\n","print('\\Script running in: ' + os.getcwd())\n","print(\"Python version: \" + sys.version)\n","print(\"Python install path: \" + sys.executable)\n","\n","import tensorflow\n","print(tensorflow.__version__)\n","import keras\n","print(keras.__version__)\n","\n","\n","# Call train function\n","if USE_PREV_WEIGHTS:\n","    file_weights_path = tmain([ 'train', '--dataset=' + PATH_DATASET, '--logs=snapshots', '--enable-augmentation', '--weights=last','--epochs=' + str(NB_OF_EPOCHS)])\n","else:\n","    file_weights_path = tmain([ 'train', '--dataset=' + PATH_DATASET, '--logs=snapshots','--enable-augmentation', '--epochs=' + str(NB_OF_EPOCHS)])\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cAaY3hgW1eFh"},"source":["# Infer RPN"]},{"cell_type":"code","metadata":{"id":"Fr0P03mu1qh_"},"source":["import os\n","import sys\n","import random\n","import math\n","import re\n","import time\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","# Root directory of the project\n","ROOT_DIR = \"/content/drive/My Drive/Colab/maskrcnn\"\n","\n","# Import Mask RCNN\n","sys.path.append(ROOT_DIR)  # To find local version of the library\n","from mrcnn import utils\n","from mrcnn import visualize\n","from mrcnn.visualize import display_images\n","import mrcnn.model as modellib\n","from mrcnn.model import log\n","\n","from samples.lego import lego\n","\n","# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eUu7jJ9i2MFl"},"source":["### Load Configuration"]},{"cell_type":"code","metadata":{"id":"YiRhbr7V2Bxf"},"source":["LEGO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"snapshots\", \"lego20200717T1532\",\"mask_rcnn_lego_0041.h5\") # file_weights_path\n","DATASET = \"eval\"\n","config = lego.LegoConfig()\n","LEGO_DIR = os.path.join(ROOT_DIR, \"datasets\", \"lego\")\n","\n","class InferenceConfig(config.__class__):\n","    # Run detection on one image at a time\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","\n","\n","config = InferenceConfig()\n","config.display()\n","\n","def get_ax(rows=1, cols=1, size=16):\n","    \"\"\"Return a Matplotlib Axes array to be used in\n","    all visualizations in the notebook. Provide a\n","    central point to control graph sizes.\n","    \n","    Adjust the size attribute to control how big to render images\n","    \"\"\"\n","    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n","    return ax"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xipHZzTm2O0l"},"source":["### Load Dataset"]},{"cell_type":"code","metadata":{"id":"w9xlxqeg2SWN"},"source":["dataset = lego.LegoDataset()\n","dataset.load_lego(LEGO_DIR, DATASET)\n","dataset.prepare()\n","print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UO32Cbk-2Uu-"},"source":["### Load Model and Weights"]},{"cell_type":"code","metadata":{"id":"d9AjL5Hx2afl"},"source":["model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n","print(\"Loading weights \", LEGO_WEIGHTS_PATH)\n","model.load_weights(LEGO_WEIGHTS_PATH, by_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VwU2faqU2dFV"},"source":["### RPN Analysis"]},{"cell_type":"code","metadata":{"id":"OCfZJ82l2fju"},"source":["if DATASET == \"eval\":\n","    image_id = dataset.get_image_id(\"0000000002.png\") # If eval set us the image with the Lego haufen\n","else:\n","    image_ids = np.random.choice(dataset.image_ids, 1)\n","    image_id = image_ids[0]\n","    \n","image, image_meta, gt_class_ids, gt_bboxes, gt_masks = modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1w0Yr5On2tT-"},"source":["# Run RPN sub-graph\n","if config.USE_RPN_ROIS:\n","    pillar = model.keras_model.get_layer(\"ROI\").output\n","\n","    # TF 1.4 and 1.9 introduce new versions of NMS. Search for all names to support TF 1.3~1.10\n","    nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression:0\")\n","    if nms_node is None:\n","        nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression/NonMaxSuppressionV2:0\")\n","    if nms_node is None: #TF 1.9-1.10\n","        nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression/NonMaxSuppressionV3:0\")\n","\n","    rpn = model.run_graph([image], [\n","        (\"rpn_class\", model.keras_model.get_layer(\"rpn_class\").output),         # Last layer in RPN with the proposed class probabilites for background or foreground per anchor\n","        (\"pre_nms_anchors\", model.ancestor(pillar, \"ROI/pre_nms_anchors:0\")),\n","        (\"refined_anchors\", model.ancestor(pillar, \"ROI/refined_anchors:0\")),\n","        (\"refined_anchors_clipped\", model.ancestor(pillar, \"ROI/refined_anchors_clipped:0\")),\n","        (\"post_nms_anchor_ix\", nms_node),                                       # Filtered anchors that have a NMS of RPN_NMS_THRESHOLD (>0.7)\n","        (\"proposals\", model.keras_model.get_layer(\"ROI\").output),               # \"ROI\" is the name of the ProposalLayers, the filtered rois proposals\n","    ], config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T0JHN1HD2mfF"},"source":["# Find the proposal that has the highest IoU on each GT box and take average of all\n","max_proposals_bbox = np.empty((gt_bboxes.shape[0], 4))\n","max_proposals_iou = np.empty((gt_bboxes.shape[0], 1))\n","\n","# Get proposals from graph\n","h, w = config.IMAGE_SHAPE[:2]\n","proposals = rpn['proposals'][0, :] * np.array([h, w, h, w])\n","\n","print(\"Best proposals are:\\n\")\n","for i, box in enumerate(gt_bboxes):\n","\n","    overlaps = utils.compute_overlaps(np.array([box.tolist()]), proposals)\n","    iou_max = np.max(overlaps, axis=1)\n","    iou_argmax = np.argmax(overlaps, axis=1)\n","    max_proposals_bbox[i] = proposals[iou_argmax]\n","    max_proposals_iou[i] = iou_max\n","\n","    y1, x1, y2, x2 = proposals[iou_argmax][0]\n","    iou = iou_max[0]\n","\n","    print(\"Proposal Bbox {}: \\t[{:.0f} {:.0f} {:.0f} {:.0f}] w={:.0f} h={:.0f} iou={:.2f}\".format(i, x1, y1, x2, y2, x2-x1, y2-y1, iou))\n","\n","\n","print(\"\\nAverage maximum IoU is: {0:0.2f}\".format(np.average(max_proposals_iou)))\n","visualize.draw_boxes(image, boxes=gt_bboxes, refined_boxes=max_proposals_bbox)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZiSucU-Fzj1h"},"source":["## Run Evaluation"]},{"cell_type":"code","metadata":{"id":"96KLDjuHznfF"},"source":["# Compute VOC-Style mAP @ IoU=0.5\n","APs = []\n","TPs = []\n","FPs = []\n","total_instances = 0\n","\n","# IoU threshold to determine a postive match\n","mAP_IOU_THRESHOLD = 0.5\n","\n","if DATASET == \"eval\":\n","    image_ids = dataset.image_ids\n","else:\n","    image_ids = np.random.choice(dataset.image_ids, 5 if config.USE_STAGE_TWO else 1)\n","\n","for image_id in image_ids:\n","\n","    # Load image and ground truth data\n","    image, image_meta, gt_class_ids, gt_bboxes, gt_masks =  modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n","\n","    # Run object detection\n","    results = model.detect([image], gt_class_ids, gt_bboxes, gt_masks, verbose=0)\n","    r = results[0]\n","\n","    ax = get_ax(1)\n","    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], dataset.class_names, gt_bboxes, gt_class_ids, \n","                                r['scores'], ax=ax, title=\"Predictions\")\n","\n","    # Compute AP, IoU ist mit den Masken berechnet, nicht mit Bboxen\n","    AP, precisions, recalls, overlaps, true_positives, false_positives = utils.compute_ap(  gt_bboxes, gt_class_ids, gt_masks,    \n","                                                                                            r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'],\n","                                                                                            iou_threshold=mAP_IOU_THRESHOLD)\n","    if true_positives == 0 and false_positives == 0:\n","        print(\"\\n*** No instances matched in {} *** \\n\".format(dataset.image_info[image_id][\"id\"]))\n","        \n","    APs.append(AP)\n","    TPs.append(true_positives)\n","    FPs.append(false_positives)\n","    total_instances += len(gt_bboxes)\n","\n","tps = int(np.sum(TPs))\n","fps = int(np.sum(FPs))\n","\n","print('TP: {:2.0f}   FP: {:2.0f}   TP/FP: {:2.1f}   TP/Total: {:2.0f}%'.format(tps, fps, 0 if fps == 0 else (tps/fps), 0 if total_instances == 0 else (100.0/total_instances)*tps))\n","print(\"mAP@\" + str(mAP_IOU_THRESHOLD)+ \": \", np.mean(APs))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ayDoE5BKGDNx"},"source":["# Download Kaggle Data to Google Drive"]},{"cell_type":"code","metadata":{"id":"ZM5-jWwbDuJH"},"source":["from google.colab import files\n","files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VOdUnZubENv_"},"source":["!pip install -q kaggle\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!ls ~/.kaggle\n","!chmod 600 /root/.kaggle/kaggle.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JC6yt0R1Ee-c"},"source":["!kaggle datasets download images6 -p /content/drive/My\\ Drive/Colab/maskrcnn/datasets/lego"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ys32uuqgFgZX"},"source":["!unzip -q /content/drive/My\\ Drive/Colab/maskrcnn/datasets/lego/images6.zip -d /content/drive/My\\ Drive/Colab/maskrcnn/datasets/lego"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_lhPzhzYGeh6"},"source":["!mv /content/drive/My\\ Drive/Colab/maskrcnn/datasets/lego/images/* /content/drive/My\\ Drive/Colab/maskrcnn/datasets/lego/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOoY9sJ_K1Sy"},"source":["# Check Environment"]},{"cell_type":"code","metadata":{"id":"xx1UXO3aK5jI"},"source":["!pip list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"akkZqOueL-Xt"},"source":["!python --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KY6HTV1bXI2w"},"source":["import tensorflow\n","print(tensorflow.__version__)\n","import keras\n","print(keras.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RnwLggeEXO7k"},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[]}]}